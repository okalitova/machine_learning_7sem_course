
[+] General Parameters:
Training data:	./learning.txt
Test data:	./test.txt
Validation data:	./val.txt
Feature vector representation: Dense.
Ranking method:	LambdaMART
Feature description file:	Unspecified. All features will be used.
Train metric:	NDCG@5
Test metric:	NDCG@5
Feature normalization: No
Model file: ./LambdaMART_100_5.txt

[+] LambdaMART's Parameters:
No. of trees: 100
No. of leaves: 5
No. of threshold candidates: 256
Learning rate: 0.1
Stop early: 100 rounds without performance gain on validation data

Reading feature file [./learning.txt]: 0... Reading feature file [./learning.txt]... [Done.]            
(72 ranked lists, 599 entries read)
Reading feature file [./val.txt]: 0... Reading feature file [./val.txt]... [Done.]            
(30 ranked lists, 191 entries read)
Reading feature file [./test.txt]: 0... Reading feature file [./test.txt]... [Done.]            
(25 ranked lists, 200 entries read)
Initializing... [Done]
---------------------------------
Training starts...
---------------------------------
#iter   | NDCG@5-T  | NDCG@5-V  | 
---------------------------------
1       | 0.6874    | 0.7406    | 
2       | 0.7625    | 0.7595    | 
3       | 0.7686    | 0.7583    | 
4       | 0.7748    | 0.7616    | 
5       | 0.7791    | 0.7598    | 
6       | 0.7827    | 0.7609    | 
7       | 0.7849    | 0.7609    | 
8       | 0.7951    | 0.7609    | 
9       | 0.7939    | 0.7626    | 
10      | 0.8       | 0.7596    | 
11      | 0.8026    | 0.7599    | 
12      | 0.8066    | 0.7585    | 
13      | 0.808     | 0.756     | 
14      | 0.807     | 0.756     | 
15      | 0.8056    | 0.7606    | 
16      | 0.8056    | 0.7606    | 
17      | 0.8065    | 0.7606    | 
18      | 0.8094    | 0.7601    | 
19      | 0.8155    | 0.7546    | 
20      | 0.8086    | 0.7456    | 
21      | 0.8162    | 0.7512    | 
22      | 0.8223    | 0.7564    | 
23      | 0.822     | 0.7564    | 
24      | 0.8243    | 0.754     | 
25      | 0.8254    | 0.7504    | 
26      | 0.8258    | 0.7534    | 
27      | 0.8264    | 0.7524    | 
28      | 0.8347    | 0.7503    | 
29      | 0.838     | 0.7512    | 
30      | 0.8399    | 0.7479    | 
31      | 0.8445    | 0.7371    | 
32      | 0.8422    | 0.7425    | 
33      | 0.8469    | 0.7456    | 
34      | 0.8527    | 0.7479    | 
35      | 0.8652    | 0.7451    | 
36      | 0.8652    | 0.7499    | 
37      | 0.8656    | 0.7475    | 
38      | 0.8656    | 0.757     | 
39      | 0.8658    | 0.7578    | 
40      | 0.8667    | 0.7629    | 
41      | 0.8667    | 0.7629    | 
42      | 0.8713    | 0.7625    | 
43      | 0.8741    | 0.7561    | 
44      | 0.8748    | 0.768     | 
45      | 0.8739    | 0.7633    | 
46      | 0.8777    | 0.7675    | 
47      | 0.8768    | 0.758     | 
48      | 0.8766    | 0.7509    | 
49      | 0.8787    | 0.7473    | 
50      | 0.88      | 0.7637    | 
51      | 0.8813    | 0.7559    | 
52      | 0.882     | 0.7415    | 
53      | 0.8847    | 0.7413    | 
54      | 0.8861    | 0.7413    | 
55      | 0.8894    | 0.743     | 
56      | 0.8885    | 0.7443    | 
57      | 0.8899    | 0.7448    | 
58      | 0.8933    | 0.7448    | 
59      | 0.8957    | 0.7417    | 
60      | 0.8959    | 0.7462    | 
61      | 0.8987    | 0.7462    | 
62      | 0.8976    | 0.7477    | 
63      | 0.8991    | 0.7513    | 
64      | 0.9015    | 0.7485    | 
65      | 0.902     | 0.7495    | 
66      | 0.9022    | 0.7495    | 
67      | 0.9043    | 0.7505    | 
68      | 0.906     | 0.7485    | 
69      | 0.9056    | 0.7451    | 
70      | 0.9058    | 0.7502    | 
71      | 0.9047    | 0.7494    | 
72      | 0.9065    | 0.7516    | 
73      | 0.9056    | 0.7474    | 
74      | 0.9101    | 0.7474    | 
75      | 0.9095    | 0.753     | 
76      | 0.9105    | 0.754     | 
77      | 0.9116    | 0.753     | 
78      | 0.9128    | 0.7524    | 
79      | 0.9144    | 0.7519    | 
80      | 0.9141    | 0.7519    | 
81      | 0.9116    | 0.7425    | 
82      | 0.9116    | 0.7425    | 
83      | 0.912     | 0.7442    | 
84      | 0.9141    | 0.7437    | 
85      | 0.9139    | 0.7437    | 
86      | 0.9205    | 0.7417    | 
87      | 0.9214    | 0.7464    | 
88      | 0.9222    | 0.7374    | 
89      | 0.9233    | 0.7388    | 
90      | 0.9221    | 0.7451    | 
91      | 0.9237    | 0.752     | 
92      | 0.9237    | 0.752     | 
93      | 0.9238    | 0.7523    | 
94      | 0.9242    | 0.7513    | 
95      | 0.9241    | 0.751     | 
96      | 0.9236    | 0.7494    | 
97      | 0.9249    | 0.7528    | 
98      | 0.9202    | 0.754     | 
99      | 0.9229    | 0.7621    | 
100     | 0.9228    | 0.7591    | 
---------------------------------
Finished sucessfully.
NDCG@5 on training data: 0.8748
NDCG@5 on validation data: 0.768
---------------------------------
NDCG@5 on test data: 0.7531

Model saved to: ./LambdaMART_100_5.txt
