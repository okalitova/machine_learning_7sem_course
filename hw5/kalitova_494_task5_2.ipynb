{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple q-learning agent with experience replay\n",
    "\n",
    "We re-write q-learning algorithm using _agentnet_ - a helper for lasagne that implements some RL techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ! pip install --upgrade https://github.com/yandexdataschool/AgentNet/archive/master.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ! pip install -r https://raw.githubusercontent.com/Lasagne/Lasagne/v0.1/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ! pip install --upgrade https://github.com/Lasagne/Lasagne/archive/master.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ! pip install Lasagne==0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS='floatX=float32'\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "%env THEANO_FLAGS='floatX=float32'\n",
    "\n",
    "#XVFB will be launched if you run on a server\n",
    "import os\n",
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\"))==0:\n",
    "    !bash ../xvfb start\n",
    "    %env DISPLAY=:1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment setup\n",
    "* Here we simply load the game and check that it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:43:28,744] Making new env: LunarLander-v2\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "make_env = lambda: gym.make(\"LunarLander-v2\")\n",
    "\n",
    "env=make_env()\n",
    "env.reset()\n",
    "\n",
    "state_shape = env.observation_space.shape\n",
    "n_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD8CAYAAAB9y7/cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f37c62763c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(env.render(\"rgb_array\"))\n",
    "del env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "from lasagne.layers import *\n",
    "from lasagne.nonlinearities import rectify\n",
    "\n",
    "\n",
    "#image observation at current tick goes here, shape = (sample_i,x,y,color)\n",
    "observation_layer = InputLayer((None,)+state_shape)\n",
    "\n",
    "\n",
    "nn = DenseLayer(observation_layer, 200, nonlinearity=rectify)\n",
    "nn = DenseLayer(nn, 200, nonlinearity=rectify)\n",
    "\n",
    "#a layer that predicts Qvalues\n",
    "qvalues_layer = DenseLayer(nn,num_units=n_actions,\n",
    "                           nonlinearity=None,name=\"q-values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Picking actions is done by yet another layer, that implements $ \\epsilon$ -greedy policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from agentnet.resolver import EpsilonGreedyResolver\n",
    "action_layer = EpsilonGreedyResolver(qvalues_layer)\n",
    "\n",
    "#set starting epsilon\n",
    "action_layer.epsilon.set_value(np.float32(0.05))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent\n",
    "\n",
    "We define an agent entirely composed of a lasagne network:\n",
    "* Observations as InputLayer(s)\n",
    "* Actions as intermediate Layer(s)\n",
    "* `policy_estimators` is \"whatever else you want to keep track of\"\n",
    "\n",
    "Each parameter can be either one layer or a list of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from agentnet.agent import Agent\n",
    "agent = Agent(observation_layers=observation_layer,\n",
    "              action_layers=action_layer,\n",
    "              policy_estimators=qvalues_layer,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[W, b, W, b, q-values.W, q-values.b]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since it's a single lasagne network, one can get it's weights, output, etc\n",
    "weights = lasagne.layers.get_all_params(action_layer,trainable=True)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and manage a pool of atari sessions to play with\n",
    "\n",
    "* To make training more stable, we shall have an entire batch of game sessions each happening independent of others\n",
    "* Why several parallel agents help training: http://arxiv.org/pdf/1602.01783v1.pdf\n",
    "* Alternative approach: store more sessions: https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:43:45,987] Making new env: LunarLander-v2\n"
     ]
    }
   ],
   "source": [
    "from agentnet.experiments.openai_gym.pool import EnvPool\n",
    "pool = EnvPool(agent,make_env,n_games=1,max_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions: [[3 3 3 3 0]]\n",
      "rewards: [[-2.19124697 -2.53940291 -2.71452379 -2.93581575  0.        ]]\n",
      "CPU times: user 8 ms, sys: 4 ms, total: 12 ms\n",
      "Wall time: 102 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#interact for 7 ticks\n",
    "obs_log,action_log,reward_log,_,_,_  = pool.interact(5)\n",
    "\n",
    "print('actions:',action_log)\n",
    "print('rewards:',reward_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we'll train on rollouts of 10 steps (required by n-step algorithms and rnns later)\n",
    "SEQ_LENGTH=10\n",
    "\n",
    "#load first sessions (this function calls interact and stores sessions in the pool)\n",
    "\n",
    "for _ in range(100):\n",
    "    pool.update(SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# q-learning\n",
    "\n",
    "We shall now define a function that replays recent game sessions and updates network weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get agent's Qvalues obtained via experience replay\n",
    "replay = pool.experience_replay.sample_session_batch(100)\n",
    "qvalues_seq = agent.get_sessions(\n",
    "    replay,\n",
    "    session_length=SEQ_LENGTH,\n",
    "    experience_replay=True,\n",
    ")[-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loss for Qlearning = (Q(s,a) - (r+gamma*Q(s',a_max)))^2, like you implemented before in lasagne.\n",
    "\n",
    "from agentnet.learning import qlearning\n",
    "elwise_mse_loss = qlearning.get_elementwise_objective(qvalues_seq,\n",
    "                                                      replay.actions[0],\n",
    "                                                      replay.rewards,\n",
    "                                                      replay.is_alive,\n",
    "                                                      gamma_or_gammas=0.99,\n",
    "                                                      n_steps=1,)\n",
    "\n",
    "#compute mean loss over \"alive\" fragments\n",
    "loss = elwise_mse_loss.sum() / replay.is_alive.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get weight updates\n",
    "updates = lasagne.updates.adam(loss,weights,learning_rate=1e-4)\n",
    "\n",
    "#compile train function\n",
    "import theano\n",
    "train_step = theano.function([],loss,updates=updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo run\n",
    "\n",
    "Play full session with an untrained agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:44:06,339] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:44:06,345] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 21:44:06,488] Starting new video recorder writing to /home/nimloth/coding/7sem/machine_learning_7sem/hw5/records/openaigym.video.0.3688.video000000.mp4\n",
      "[2017-11-04 21:44:09,235] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 76 timesteps with reward=-617.390574482624\n"
     ]
    }
   ],
   "source": [
    "#for MountainCar-v0 evaluation session is cropped to 200 ticks\n",
    "untrained_reward = pool.evaluate(save_path=\"./records\",record_video=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"480\" controls>\n",
       "  <source src=\"./records/openaigym.video.0.3688.video000000.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show video\n",
    "from IPython.display import HTML\n",
    "import os\n",
    "\n",
    "video_names = list(filter(lambda s:s.endswith(\".mp4\"),os.listdir(\"./records/\")))\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(\"./records/\"+video_names[-1])) #this may or may not be _last_ video. Try other indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epoch_counter = 1 #starting epoch\n",
    "rewards = {} #full game rewards\n",
    "target_score = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 98/10000 [00:06<10:07, 16.30it/s][2017-11-04 21:44:16,606] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:44:16,617] Clearing 4 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 96 timesteps with reward=-175.8561231188205\n",
      "Episode finished after 75 timesteps with reward=-117.21432035374063\n",
      "Episode finished after 89 timesteps with reward=-322.612053233502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:44:16,944] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      "  1%|          | 102/10000 [00:06<10:43, 15.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=100\tepsilon=0.910\n",
      "Current score(mean over 3) = -205.227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 199/10000 [00:12<09:51, 16.57it/s][2017-11-04 21:44:22,497] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:44:22,501] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 21:44:22,706] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      "  2%|▏         | 201/10000 [00:12<10:01, 16.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 93 timesteps with reward=-74.76010765098812\n",
      "Episode finished after 74 timesteps with reward=-193.68500793752838\n",
      "Episode finished after 96 timesteps with reward=-354.87239511823486\n",
      "iter=200\tepsilon=0.828\n",
      "Current score(mean over 3) = -207.773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 299/10000 [00:18<10:14, 15.80it/s][2017-11-04 21:44:29,413] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:44:29,417] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 21:44:29,759] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 214 timesteps with reward=-181.16191874785338\n",
      "Episode finished after 96 timesteps with reward=-352.26739986826044\n",
      "Episode finished after 104 timesteps with reward=-279.2825033289703\n",
      "iter=300\tepsilon=0.754\n",
      "Current score(mean over 3) = -270.904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 399/10000 [00:24<09:51, 16.22it/s][2017-11-04 21:44:35,093] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:44:35,097] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 21:44:35,375] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      "  4%|▍         | 401/10000 [00:25<09:58, 16.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 145 timesteps with reward=-247.2003151186183\n",
      "Episode finished after 110 timesteps with reward=-213.98854903434164\n",
      "Episode finished after 103 timesteps with reward=-107.95190767523809\n",
      "iter=400\tepsilon=0.687\n",
      "Current score(mean over 3) = -189.714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 499/10000 [00:31<09:51, 16.06it/s][2017-11-04 21:44:41,575] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:44:41,581] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 21:44:41,968] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 147 timesteps with reward=-218.48269189539647\n",
      "Episode finished after 85 timesteps with reward=-238.2447884938585\n",
      "Episode finished after 121 timesteps with reward=-184.15607754230263\n",
      "iter=500\tepsilon=0.626\n",
      "Current score(mean over 3) = -213.628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 598/10000 [00:39<10:21, 15.13it/s][2017-11-04 21:44:50,138] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:44:50,143] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 133 timesteps with reward=-219.4805282109657\n",
      "Episode finished after 154 timesteps with reward=-130.1275150612402\n",
      "Episode finished after 127 timesteps with reward=-142.01955772406887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:44:50,483] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      "  6%|▌         | 602/10000 [00:40<10:27, 14.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=600\tepsilon=0.571\n",
      "Current score(mean over 3) = -163.876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 698/10000 [00:47<10:33, 14.69it/s][2017-11-04 21:44:58,082] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:44:58,085] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 113 timesteps with reward=-272.3665539634467\n",
      "Episode finished after 124 timesteps with reward=-237.90117881383\n",
      "Episode finished after 144 timesteps with reward=-228.28430370814092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:44:58,416] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      "  7%|▋         | 702/10000 [00:48<10:37, 14.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=700\tepsilon=0.522\n",
      "Current score(mean over 3) = -246.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 799/10000 [00:56<10:49, 14.17it/s][2017-11-04 21:45:06,930] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:45:06,934] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 340 timesteps with reward=-298.73973157892243\n",
      "Episode finished after 206 timesteps with reward=-465.9060590734472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:45:07,838] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      "  8%|▊         | 801/10000 [00:57<11:00, 13.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 152 timesteps with reward=-233.44349570192864\n",
      "iter=800\tepsilon=0.477\n",
      "Current score(mean over 3) = -332.696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 898/10000 [01:08<11:30, 13.17it/s][2017-11-04 21:45:18,719] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:45:18,723] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 221 timesteps with reward=-283.5669916401151\n",
      "Episode finished after 342 timesteps with reward=-414.4710872798364\n",
      "Episode finished after 127 timesteps with reward=-77.16770995868976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:45:19,453] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      "  9%|▉         | 902/10000 [01:09<11:37, 13.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=900\tepsilon=0.436\n",
      "Current score(mean over 3) = -258.402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 998/10000 [01:18<11:46, 12.74it/s][2017-11-04 21:45:28,923] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:45:28,927] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 225 timesteps with reward=-291.2325435903788\n",
      "Episode finished after 406 timesteps with reward=-527.1861079558438\n",
      "Episode finished after 369 timesteps with reward=-139.78431966764714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:45:30,136] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 10%|█         | 1002/10000 [01:19<11:57, 12.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1000\tepsilon=0.399\n",
      "Current score(mean over 3) = -319.401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1099/10000 [01:30<12:10, 12.19it/s][2017-11-04 21:45:40,652] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:45:40,656] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 213 timesteps with reward=-209.71826234487713\n",
      "Episode finished after 402 timesteps with reward=-300.1090374152269\n",
      "Episode finished after 148 timesteps with reward=-206.49433570408974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:45:41,401] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 11%|█         | 1101/10000 [01:31<12:16, 12.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1100\tepsilon=0.366\n",
      "Current score(mean over 3) = -238.774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1199/10000 [01:40<12:18, 11.92it/s][2017-11-04 21:45:51,137] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:45:51,141] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 423 timesteps with reward=-218.83044621427933\n",
      "Episode finished after 1000 timesteps with reward=-57.571140522216425\n",
      "Episode finished after 438 timesteps with reward=-298.74798433196065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:45:54,595] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 12%|█▏        | 1201/10000 [01:44<12:44, 11.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1200\tepsilon=0.336\n",
      "Current score(mean over 3) = -191.717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 1299/10000 [01:59<13:19, 10.88it/s][2017-11-04 21:46:09,992] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:46:09,996] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 21:46:10,695] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 13%|█▎        | 1301/10000 [02:00<13:25, 10.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 179 timesteps with reward=-297.1729653367444\n",
      "Episode finished after 295 timesteps with reward=-350.47405792308405\n",
      "Episode finished after 142 timesteps with reward=-104.82398941323528\n",
      "iter=1300\tepsilon=0.309\n",
      "Current score(mean over 3) = -250.824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1398/10000 [02:10<13:20, 10.75it/s][2017-11-04 21:46:20,652] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:46:20,657] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 505 timesteps with reward=-162.46510855164718\n",
      "Episode finished after 1000 timesteps with reward=-164.9939190978329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:46:27,271] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 14%|█▍        | 1401/10000 [02:16<14:00, 10.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-117.5601886346043\n",
      "iter=1400\tepsilon=0.284\n",
      "Current score(mean over 3) = -148.340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 1499/10000 [02:27<13:53, 10.19it/s][2017-11-04 21:46:37,569] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:46:37,573] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 135 timesteps with reward=-255.05165580622128\n",
      "Episode finished after 426 timesteps with reward=-345.4737497564911\n",
      "Episode finished after 245 timesteps with reward=-224.79546391465118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:46:38,602] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 15%|█▌        | 1501/10000 [02:28<13:59, 10.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1500\tepsilon=0.262\n",
      "Current score(mean over 3) = -275.107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 1598/10000 [02:38<13:55, 10.06it/s][2017-11-04 21:46:49,441] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:46:49,446] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 359 timesteps with reward=-169.1535908752931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:46:53,829] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 16%|█▌        | 1601/10000 [02:43<14:17,  9.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 859 timesteps with reward=117.02462914778152\n",
      "Episode finished after 465 timesteps with reward=-175.983938641693\n",
      "iter=1600\tepsilon=0.242\n",
      "Current score(mean over 3) = -76.038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1698/10000 [02:56<14:22,  9.62it/s][2017-11-04 21:47:07,096] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:47:07,101] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 255 timesteps with reward=-62.088849316712086\n",
      "Episode finished after 220 timesteps with reward=-212.19411406208576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:47:08,848] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 17%|█▋        | 1701/10000 [02:58<14:31,  9.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 672 timesteps with reward=-354.2608501185065\n",
      "iter=1700\tepsilon=0.224\n",
      "Current score(mean over 3) = -209.515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 1798/10000 [03:10<14:27,  9.46it/s][2017-11-04 21:47:20,815] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:47:20,819] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 21:47:24,706] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 18%|█▊        | 1801/10000 [03:14<14:45,  9.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-96.37195319244412\n",
      "Episode finished after 440 timesteps with reward=-150.73291358657985\n",
      "Episode finished after 163 timesteps with reward=-129.30550214642324\n",
      "iter=1800\tepsilon=0.207\n",
      "Current score(mean over 3) = -125.470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 1899/10000 [03:28<14:51,  9.09it/s][2017-11-04 21:47:39,579] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:47:39,583] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 375 timesteps with reward=-123.06932376026136\n",
      "Episode finished after 1000 timesteps with reward=-216.51694509413625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:47:43,079] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 19%|█▉        | 1900/10000 [03:32<15:06,  8.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 189 timesteps with reward=-160.14692250897437\n",
      "iter=1900\tepsilon=0.192\n",
      "Current score(mean over 3) = -166.578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 1999/10000 [03:44<14:57,  8.92it/s][2017-11-04 21:47:54,734] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:47:54,738] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 294 timesteps with reward=-78.32867679947047\n",
      "Episode finished after 1000 timesteps with reward=-145.72099192974167\n",
      "Episode finished after 279 timesteps with reward=-183.56907187253194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:47:57,216] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 20%|██        | 2001/10000 [03:46<15:07,  8.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=2000\tepsilon=0.179\n",
      "Current score(mean over 3) = -135.873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 2099/10000 [04:03<15:17,  8.61it/s][2017-11-04 21:48:14,474] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:48:14,478] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-179.49182176225062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:48:19,662] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 21%|██        | 2100/10000 [04:09<15:37,  8.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-108.15416068032542\n",
      "Episode finished after 245 timesteps with reward=-258.27197449541745\n",
      "iter=2100\tepsilon=0.166\n",
      "Current score(mean over 3) = -181.973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2199/10000 [04:24<15:38,  8.31it/s][2017-11-04 21:48:35,212] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:48:35,216] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 759 timesteps with reward=110.2457204000158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:48:39,598] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 22%|██▏       | 2201/10000 [04:29<15:54,  8.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-150.76960928521876\n",
      "Episode finished after 175 timesteps with reward=-136.85704447196775\n",
      "iter=2200\tepsilon=0.155\n",
      "Current score(mean over 3) = -59.127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 2299/10000 [04:44<15:53,  8.08it/s][2017-11-04 21:48:55,122] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:48:55,126] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-154.65235668664855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:48:58,691] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 23%|██▎       | 2301/10000 [04:48<16:05,  7.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 292 timesteps with reward=-257.4752986649988\n",
      "Episode finished after 308 timesteps with reward=-301.8522049813717\n",
      "iter=2300\tepsilon=0.145\n",
      "Current score(mean over 3) = -237.993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 2399/10000 [05:08<16:17,  7.77it/s][2017-11-04 21:49:19,134] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:49:19,139] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-149.62567897049442\n",
      "Episode finished after 190 timesteps with reward=-89.59505422179646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:49:21,934] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 24%|██▍       | 2401/10000 [05:11<16:26,  7.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 144 timesteps with reward=-182.89929966908852\n",
      "iter=2400\tepsilon=0.136\n",
      "Current score(mean over 3) = -140.707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 2499/10000 [05:28<16:25,  7.61it/s][2017-11-04 21:49:38,956] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:49:38,962] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-132.42775156950262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:49:45,059] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 25%|██▌       | 2500/10000 [05:34<16:43,  7.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 406 timesteps with reward=-147.95018360746838\n",
      "Episode finished after 173 timesteps with reward=-64.73322615491634\n",
      "iter=2500\tepsilon=0.128\n",
      "Current score(mean over 3) = -115.037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 2599/10000 [05:50<16:38,  7.41it/s][2017-11-04 21:50:01,176] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:50:01,180] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-132.89706752944016\n",
      "Episode finished after 1000 timesteps with reward=-116.54195767255422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:50:10,979] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 26%|██▌       | 2600/10000 [06:00<17:06,  7.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-128.36819445270103\n",
      "iter=2600\tepsilon=0.121\n",
      "Current score(mean over 3) = -125.936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 2699/10000 [06:19<17:05,  7.12it/s][2017-11-04 21:50:29,732] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:50:29,736] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-97.49870514199944\n",
      "Episode finished after 245 timesteps with reward=-323.7940588670819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:50:34,126] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 27%|██▋       | 2700/10000 [06:23<17:17,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-144.7355564338846\n",
      "iter=2700\tepsilon=0.114\n",
      "Current score(mean over 3) = -188.676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 2799/10000 [06:41<17:12,  6.97it/s][2017-11-04 21:50:51,890] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:50:51,894] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 21:50:52,915] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 28%|██▊       | 2801/10000 [06:42<17:14,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 341 timesteps with reward=-291.6913366808876\n",
      "Episode finished after 303 timesteps with reward=-241.2551150147586\n",
      "Episode finished after 245 timesteps with reward=-293.5933671192848\n",
      "iter=2800\tepsilon=0.108\n",
      "Current score(mean over 3) = -275.513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 2899/10000 [06:57<17:02,  6.94it/s][2017-11-04 21:51:08,028] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:51:08,033] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 21:51:10,743] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 29%|██▉       | 2900/10000 [07:00<17:09,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-146.7229966988015\n",
      "Episode finished after 236 timesteps with reward=-257.44424387480893\n",
      "Episode finished after 220 timesteps with reward=-163.4074884760995\n",
      "iter=2900\tepsilon=0.102\n",
      "Current score(mean over 3) = -189.192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 2999/10000 [07:17<17:00,  6.86it/s][2017-11-04 21:51:27,725] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:51:27,729] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 348 timesteps with reward=-321.47387815718173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:51:33,565] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 30%|███       | 3000/10000 [07:23<17:13,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-146.78283051513367\n",
      "Episode finished after 1000 timesteps with reward=-124.71625986479583\n",
      "iter=3000\tepsilon=0.097\n",
      "Current score(mean over 3) = -197.658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 3099/10000 [07:42<17:09,  6.70it/s][2017-11-04 21:51:52,997] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:51:53,001] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-128.97840311006286\n",
      "Episode finished after 1000 timesteps with reward=-134.30125536734434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:51:59,082] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 31%|███       | 3102/10000 [07:48<17:22,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 470 timesteps with reward=-288.2526592074047\n",
      "iter=3100\tepsilon=0.093\n",
      "Current score(mean over 3) = -183.844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 3199/10000 [08:05<17:11,  6.59it/s][2017-11-04 21:52:15,911] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:52:15,916] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-177.50179587058358\n",
      "Episode finished after 1000 timesteps with reward=-188.10766346339238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:52:26,438] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 32%|███▏      | 3200/10000 [08:16<17:34,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-128.3653357617649\n",
      "iter=3200\tepsilon=0.089\n",
      "Current score(mean over 3) = -164.658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3299/10000 [08:36<17:29,  6.38it/s][2017-11-04 21:52:47,470] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:52:47,474] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 424 timesteps with reward=-193.61349263756728\n",
      "Episode finished after 391 timesteps with reward=-301.2182738814723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:52:51,499] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 33%|███▎      | 3301/10000 [08:41<17:37,  6.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-166.61953995640178\n",
      "iter=3300\tepsilon=0.085\n",
      "Current score(mean over 3) = -220.484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 3399/10000 [08:56<17:22,  6.33it/s][2017-11-04 21:53:07,524] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:53:07,528] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 93 timesteps with reward=-532.428294554547\n",
      "Episode finished after 1000 timesteps with reward=-160.04764027140985\n",
      "Episode finished after 433 timesteps with reward=-155.41093905806747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:53:10,776] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 34%|███▍      | 3401/10000 [09:00<17:28,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=3400\tepsilon=0.082\n",
      "Current score(mean over 3) = -282.629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 3498/10000 [09:14<17:11,  6.31it/s][2017-11-04 21:53:25,293] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:53:25,297] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 96 timesteps with reward=-303.73488491046606\n",
      "Episode finished after 1000 timesteps with reward=-138.4373765576737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:53:30,503] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 35%|███▌      | 3501/10000 [09:20<17:19,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-126.33596033919608\n",
      "iter=3500\tepsilon=0.079\n",
      "Current score(mean over 3) = -189.503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 3599/10000 [09:32<16:58,  6.28it/s][2017-11-04 21:53:43,492] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:53:43,496] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 21:53:47,679] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 36%|███▌      | 3601/10000 [09:37<17:06,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-138.7492856009859\n",
      "Episode finished after 1000 timesteps with reward=-157.14819941925626\n",
      "Episode finished after 86 timesteps with reward=-377.7682241809369\n",
      "iter=3600\tepsilon=0.076\n",
      "Current score(mean over 3) = -224.555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 3699/10000 [09:53<16:51,  6.23it/s][2017-11-04 21:54:04,052] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:54:04,056] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-80.1781062964584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:54:11,022] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 37%|███▋      | 3702/10000 [10:00<17:02,  6.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-113.85900563948357\n",
      "Episode finished after 1000 timesteps with reward=-89.8398668543009\n",
      "iter=3700\tepsilon=0.073\n",
      "Current score(mean over 3) = -94.626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3799/10000 [10:14<16:43,  6.18it/s][2017-11-04 21:54:25,349] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:54:25,353] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 21:54:31,026] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 38%|███▊      | 3801/10000 [10:20<16:52,  6.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-95.30726656927708\n",
      "Episode finished after 260 timesteps with reward=-99.284839418445\n",
      "Episode finished after 1000 timesteps with reward=-131.75913038407433\n",
      "iter=3800\tepsilon=0.071\n",
      "Current score(mean over 3) = -108.784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 3899/10000 [10:38<16:38,  6.11it/s][2017-11-04 21:54:48,961] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:54:48,965] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-148.52664281659645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:54:54,832] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 39%|███▉      | 3901/10000 [10:44<16:47,  6.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-99.95530723359653\n",
      "Episode finished after 117 timesteps with reward=-355.41114649695453\n",
      "iter=3900\tepsilon=0.069\n",
      "Current score(mean over 3) = -201.298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 3999/10000 [11:01<16:33,  6.04it/s][2017-11-04 21:55:12,266] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:55:12,271] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-149.28021072877513\n",
      "Episode finished after 1000 timesteps with reward=-126.61615098191315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:55:19,983] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 40%|████      | 4001/10000 [11:09<16:44,  5.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-142.28750722079965\n",
      "iter=4000\tepsilon=0.067\n",
      "Current score(mean over 3) = -139.395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 4099/10000 [11:28<16:31,  5.95it/s][2017-11-04 21:55:39,150] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:55:39,154] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-145.2922309067363\n",
      "Episode finished after 1000 timesteps with reward=-183.752312286913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:55:48,932] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 41%|████      | 4100/10000 [11:38<16:45,  5.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-166.74787354503906\n",
      "iter=4100\tepsilon=0.066\n",
      "Current score(mean over 3) = -165.264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 4199/10000 [11:54<16:26,  5.88it/s][2017-11-04 21:56:04,889] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:56:04,894] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 265 timesteps with reward=-147.31468495991868\n",
      "Episode finished after 1000 timesteps with reward=-224.18848728405953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:56:09,380] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 42%|████▏     | 4202/10000 [11:59<16:32,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 851 timesteps with reward=-304.39159568698983\n",
      "iter=4200\tepsilon=0.064\n",
      "Current score(mean over 3) = -225.298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 4299/10000 [12:15<16:15,  5.85it/s][2017-11-04 21:56:26,080] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:56:26,084] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 21:56:29,970] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 43%|████▎     | 4301/10000 [12:19<16:20,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 537 timesteps with reward=-207.87488632098163\n",
      "Episode finished after 795 timesteps with reward=-284.6264881823299\n",
      "Episode finished after 806 timesteps with reward=-305.2742581496743\n",
      "iter=4300\tepsilon=0.063\n",
      "Current score(mean over 3) = -265.925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4399/10000 [12:34<16:00,  5.83it/s][2017-11-04 21:56:44,944] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:56:44,948] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-201.99518184139916\n",
      "Episode finished after 1000 timesteps with reward=-152.14326583004677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:56:51,336] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 44%|████▍     | 4401/10000 [12:41<16:08,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-211.60084744823328\n",
      "iter=4400\tepsilon=0.062\n",
      "Current score(mean over 3) = -188.580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 4499/10000 [12:58<15:51,  5.78it/s][2017-11-04 21:57:09,141] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:57:09,145] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-99.05654804035132\n",
      "Episode finished after 1000 timesteps with reward=-146.0589163365563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:57:18,405] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 45%|████▌     | 4500/10000 [13:07<16:03,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-111.15766904461096\n",
      "iter=4500\tepsilon=0.061\n",
      "Current score(mean over 3) = -118.758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 4599/10000 [13:27<15:48,  5.70it/s][2017-11-04 21:57:38,085] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:57:38,089] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-142.16515854494278\n",
      "Episode finished after 1000 timesteps with reward=-145.64130198544245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:57:47,098] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 46%|████▌     | 4602/10000 [13:36<15:58,  5.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-127.2874234319495\n",
      "iter=4600\tepsilon=0.060\n",
      "Current score(mean over 3) = -138.365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 4699/10000 [13:53<15:40,  5.64it/s][2017-11-04 21:58:04,166] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:58:04,170] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-153.79981305332237\n",
      "Episode finished after 1000 timesteps with reward=-121.61555441101787\n",
      "Episode finished after 1000 timesteps with reward=-118.0501962796667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:58:12,241] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 47%|████▋     | 4700/10000 [14:01<15:49,  5.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=4700\tepsilon=0.059\n",
      "Current score(mean over 3) = -131.155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 4799/10000 [14:20<15:33,  5.57it/s][2017-11-04 21:58:31,545] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:58:31,549] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-113.10928700338297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:58:40,210] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 48%|████▊     | 4802/10000 [14:29<15:41,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-143.77551985207518\n",
      "Episode finished after 1000 timesteps with reward=-116.52353396020818\n",
      "iter=4800\tepsilon=0.058\n",
      "Current score(mean over 3) = -124.469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 4899/10000 [14:45<15:22,  5.53it/s][2017-11-04 21:58:56,514] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:58:56,518] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-102.76459905341358\n",
      "Episode finished after 1000 timesteps with reward=-93.57418778678633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:59:04,923] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 49%|████▉     | 4900/10000 [14:54<15:31,  5.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-128.3352989779615\n",
      "iter=4900\tepsilon=0.057\n",
      "Current score(mean over 3) = -108.225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 4999/10000 [15:14<15:14,  5.47it/s][2017-11-04 21:59:24,683] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:59:24,688] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-143.25462487770392\n",
      "Episode finished after 1000 timesteps with reward=-151.56184947509442\n",
      "Episode finished after 1000 timesteps with reward=-131.87091344114452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:59:31,407] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 50%|█████     | 5001/10000 [15:21<15:20,  5.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=5000\tepsilon=0.056\n",
      "Current score(mean over 3) = -142.229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 5099/10000 [15:35<14:59,  5.45it/s][2017-11-04 21:59:46,255] Making new env: LunarLander-v2\n",
      "[2017-11-04 21:59:46,261] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-167.98747658566083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:59:54,962] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 51%|█████     | 5101/10000 [15:44<15:07,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-130.68325541934018\n",
      "Episode finished after 1000 timesteps with reward=-146.95162086844576\n",
      "iter=5100\tepsilon=0.056\n",
      "Current score(mean over 3) = -148.541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 5199/10000 [16:00<14:47,  5.41it/s][2017-11-04 22:00:11,383] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:00:11,388] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-140.55454096412024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:00:16,780] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 52%|█████▏    | 5200/10000 [16:06<14:52,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-119.04017733076974\n",
      "Episode finished after 167 timesteps with reward=-386.74237634346093\n",
      "iter=5200\tepsilon=0.055\n",
      "Current score(mean over 3) = -215.446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 5299/10000 [16:24<14:33,  5.38it/s][2017-11-04 22:00:35,128] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:00:35,132] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-151.6936671804015\n",
      "Episode finished after 1000 timesteps with reward=-143.59774310065077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:00:42,103] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 53%|█████▎    | 5300/10000 [16:31<14:39,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-156.73138353208256\n",
      "iter=5300\tepsilon=0.055\n",
      "Current score(mean over 3) = -150.674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 5399/10000 [16:51<14:21,  5.34it/s][2017-11-04 22:01:02,069] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:01:02,073] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-169.60768419910534\n",
      "Episode finished after 1000 timesteps with reward=-174.67419057399707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:01:10,016] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 54%|█████▍    | 5400/10000 [16:59<14:28,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-131.90906835402424\n",
      "iter=5400\tepsilon=0.054\n",
      "Current score(mean over 3) = -158.730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 5499/10000 [17:16<14:08,  5.30it/s][2017-11-04 22:01:27,576] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:01:27,580] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-162.75385679064425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:01:33,211] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 55%|█████▌    | 5500/10000 [17:22<14:13,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-179.21424358715265\n",
      "Episode finished after 135 timesteps with reward=-319.40500866333934\n",
      "iter=5500\tepsilon=0.054\n",
      "Current score(mean over 3) = -220.458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 5599/10000 [17:38<13:51,  5.29it/s][2017-11-04 22:01:49,124] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:01:49,128] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-164.47158136159467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:01:58,255] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 56%|█████▌    | 5600/10000 [17:47<13:59,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-182.2678016014383\n",
      "Episode finished after 1000 timesteps with reward=-157.05388061037337\n",
      "iter=5600\tepsilon=0.054\n",
      "Current score(mean over 3) = -167.931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 5699/10000 [18:02<13:37,  5.26it/s][2017-11-04 22:02:13,552] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:02:13,557] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-139.18829629506473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:02:23,240] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 57%|█████▋    | 5701/10000 [18:12<13:44,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-152.14510330667767\n",
      "Episode finished after 1000 timesteps with reward=-172.06546816845352\n",
      "iter=5700\tepsilon=0.053\n",
      "Current score(mean over 3) = -154.466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 5799/10000 [18:31<13:25,  5.22it/s][2017-11-04 22:02:41,862] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:02:41,866] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-152.13176117777735\n",
      "Episode finished after 1000 timesteps with reward=-176.40797760703643\n",
      "Episode finished after 1000 timesteps with reward=-145.1055572515106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:02:49,460] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 58%|█████▊    | 5800/10000 [18:39<13:30,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=5800\tepsilon=0.053\n",
      "Current score(mean over 3) = -157.882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 5899/10000 [18:56<13:09,  5.19it/s][2017-11-04 22:03:06,845] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:03:06,849] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-171.7060216375705\n",
      "Episode finished after 1000 timesteps with reward=-156.30438698884873\n",
      "Episode finished after 1000 timesteps with reward=-147.62665841969815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:03:14,871] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 59%|█████▉    | 5901/10000 [19:04<13:15,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=5900\tepsilon=0.053\n",
      "Current score(mean over 3) = -158.546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 5999/10000 [19:21<12:54,  5.17it/s][2017-11-04 22:03:31,871] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:03:31,875] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-160.4031131675009\n",
      "Episode finished after 1000 timesteps with reward=-144.3079125873205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:03:38,856] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 60%|██████    | 6000/10000 [19:28<12:58,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-212.8494984291083\n",
      "iter=6000\tepsilon=0.052\n",
      "Current score(mean over 3) = -172.520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 6099/10000 [19:44<12:37,  5.15it/s][2017-11-04 22:03:55,388] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:03:55,392] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-187.7728369599301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:04:05,403] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 61%|██████    | 6100/10000 [19:54<12:43,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-159.96188645375696\n",
      "Episode finished after 1000 timesteps with reward=-130.2402526676239\n",
      "iter=6100\tepsilon=0.052\n",
      "Current score(mean over 3) = -159.325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 6199/10000 [20:12<12:23,  5.11it/s][2017-11-04 22:04:23,265] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:04:23,269] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-168.89195988488612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:04:29,744] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 62%|██████▏   | 6201/10000 [20:19<12:27,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-128.68204102982375\n",
      "Episode finished after 1000 timesteps with reward=-157.10549192321471\n",
      "iter=6200\tepsilon=0.052\n",
      "Current score(mean over 3) = -151.560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 6299/10000 [20:36<12:06,  5.09it/s][2017-11-04 22:04:47,558] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:04:47,562] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-153.69199773307676\n",
      "Episode finished after 1000 timesteps with reward=-167.47681809603802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:04:55,605] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 63%|██████▎   | 6300/10000 [20:45<12:11,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-147.43108457861405\n",
      "iter=6300\tepsilon=0.052\n",
      "Current score(mean over 3) = -156.200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 6399/10000 [21:04<11:51,  5.06it/s][2017-11-04 22:05:15,363] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:05:15,367] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-178.56598779634314\n",
      "Episode finished after 940 timesteps with reward=-272.8279610166914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:05:22,436] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 64%|██████▍   | 6401/10000 [21:12<11:55,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-185.16080021210843\n",
      "iter=6400\tepsilon=0.052\n",
      "Current score(mean over 3) = -212.185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 6499/10000 [21:29<11:34,  5.04it/s][2017-11-04 22:05:40,007] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:05:40,011] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-171.86540386907114\n",
      "Episode finished after 1000 timesteps with reward=-158.38760445525375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:05:47,229] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 65%|██████▌   | 6501/10000 [21:36<11:38,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-151.88006396587522\n",
      "iter=6500\tepsilon=0.051\n",
      "Current score(mean over 3) = -160.711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 6599/10000 [21:57<11:19,  5.01it/s][2017-11-04 22:06:08,471] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:06:08,478] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-149.28062937563473\n",
      "Episode finished after 1000 timesteps with reward=-150.09258463136177\n",
      "Episode finished after 1000 timesteps with reward=-200.91387089340301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:06:17,955] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 66%|██████▌   | 6600/10000 [22:07<11:23,  4.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=6600\tepsilon=0.051\n",
      "Current score(mean over 3) = -166.762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6699/10000 [22:26<11:03,  4.98it/s][2017-11-04 22:06:36,652] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:06:36,658] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-154.59206206522495\n",
      "Episode finished after 1000 timesteps with reward=-144.56531722352952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:06:43,766] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 67%|██████▋   | 6700/10000 [22:33<11:06,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-129.13272188977913\n",
      "iter=6700\tepsilon=0.051\n",
      "Current score(mean over 3) = -142.763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 6799/10000 [22:51<10:45,  4.96it/s][2017-11-04 22:07:02,682] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:07:02,686] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-137.66547962455212\n",
      "Episode finished after 1000 timesteps with reward=-178.85592206774675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:07:09,995] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 68%|██████▊   | 6800/10000 [22:59<10:49,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-123.1405207519928\n",
      "iter=6800\tepsilon=0.051\n",
      "Current score(mean over 3) = -146.554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 6899/10000 [23:17<10:28,  4.94it/s][2017-11-04 22:07:27,980] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:07:27,988] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-181.55401406388762\n",
      "Episode finished after 1000 timesteps with reward=-158.18335793780318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:07:37,927] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 69%|██████▉   | 6900/10000 [23:27<10:32,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-172.3921549015546\n",
      "iter=6900\tepsilon=0.051\n",
      "Current score(mean over 3) = -170.710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 6999/10000 [23:48<10:12,  4.90it/s][2017-11-04 22:07:59,623] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:07:59,628] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-170.60606656733137\n",
      "Episode finished after 1000 timesteps with reward=-121.98952491051783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:08:06,995] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 70%|███████   | 7000/10000 [23:56<10:15,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-129.58739865146094\n",
      "iter=7000\tepsilon=0.051\n",
      "Current score(mean over 3) = -140.728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 7099/10000 [24:15<09:54,  4.88it/s][2017-11-04 22:08:26,569] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:08:26,575] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-146.52403226320416\n",
      "Episode finished after 1000 timesteps with reward=-130.09266723361378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:08:35,691] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 71%|███████   | 7100/10000 [24:25<09:58,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-114.89642282004087\n",
      "iter=7100\tepsilon=0.051\n",
      "Current score(mean over 3) = -130.504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 7199/10000 [24:41<09:36,  4.86it/s][2017-11-04 22:08:52,217] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:08:52,221] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-156.67286367160352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:08:59,491] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 72%|███████▏  | 7201/10000 [24:49<09:38,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-134.45553271518617\n",
      "Episode finished after 1000 timesteps with reward=-114.45967021534022\n",
      "iter=7200\tepsilon=0.051\n",
      "Current score(mean over 3) = -135.196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 7299/10000 [25:07<09:17,  4.84it/s][2017-11-04 22:09:17,975] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:09:17,980] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-127.69352247523804\n",
      "Episode finished after 1000 timesteps with reward=-151.29375588381671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:09:25,534] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 73%|███████▎  | 7301/10000 [25:15<09:20,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-135.04901587942305\n",
      "iter=7300\tepsilon=0.051\n",
      "Current score(mean over 3) = -138.012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 7399/10000 [25:32<08:58,  4.83it/s][2017-11-04 22:09:42,760] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:09:42,765] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-122.7080597153495\n",
      "Episode finished after 1000 timesteps with reward=-164.63388290690168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:09:51,798] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 74%|███████▍  | 7400/10000 [25:41<09:01,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-140.14525301323687\n",
      "iter=7400\tepsilon=0.051\n",
      "Current score(mean over 3) = -142.496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 7499/10000 [26:00<08:40,  4.81it/s][2017-11-04 22:10:10,645] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:10:10,649] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-109.57986230394336\n",
      "Episode finished after 1000 timesteps with reward=-115.23781157528636\n",
      "Episode finished after 1000 timesteps with reward=-149.8640271173472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:10:19,850] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 75%|███████▌  | 7500/10000 [26:09<08:43,  4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=7500\tepsilon=0.051\n",
      "Current score(mean over 3) = -124.894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 7599/10000 [26:28<08:21,  4.78it/s][2017-11-04 22:10:39,102] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:10:39,107] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-152.65677200039\n",
      "Episode finished after 1000 timesteps with reward=-132.39248715948213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:10:47,564] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 76%|███████▌  | 7600/10000 [26:37<08:24,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-124.47848935983181\n",
      "iter=7600\tepsilon=0.050\n",
      "Current score(mean over 3) = -136.509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 7699/10000 [26:58<08:03,  4.76it/s][2017-11-04 22:11:08,958] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:11:08,962] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-163.51036066754318\n",
      "Episode finished after 1000 timesteps with reward=-128.60083025521817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:11:15,636] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 77%|███████▋  | 7701/10000 [27:05<08:05,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-118.31860645642702\n",
      "iter=7700\tepsilon=0.050\n",
      "Current score(mean over 3) = -136.810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7799/10000 [27:22<07:43,  4.75it/s][2017-11-04 22:11:33,192] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:11:33,197] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-136.54525447462854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:11:40,332] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 78%|███████▊  | 7801/10000 [27:30<07:45,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-131.59360226862427\n",
      "Episode finished after 1000 timesteps with reward=-125.19236456674409\n",
      "iter=7800\tepsilon=0.050\n",
      "Current score(mean over 3) = -131.110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 7899/10000 [27:47<07:23,  4.74it/s][2017-11-04 22:11:57,841] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:11:57,845] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-180.08412368352379\n",
      "Episode finished after 1000 timesteps with reward=-153.4518463180011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:12:06,419] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 79%|███████▉  | 7901/10000 [27:56<07:25,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-151.4020142508922\n",
      "iter=7900\tepsilon=0.050\n",
      "Current score(mean over 3) = -161.646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 7999/10000 [28:15<07:04,  4.72it/s][2017-11-04 22:12:26,476] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:12:26,480] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-144.93152752794555\n",
      "Episode finished after 1000 timesteps with reward=-135.88455640488365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:12:36,464] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 80%|████████  | 8000/10000 [28:26<07:06,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-132.8593990485661\n",
      "iter=8000\tepsilon=0.050\n",
      "Current score(mean over 3) = -137.892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 8099/10000 [28:44<06:44,  4.70it/s][2017-11-04 22:12:54,904] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:12:54,908] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-168.42710506449802\n",
      "Episode finished after 1000 timesteps with reward=-177.79215526660857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:13:05,054] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 81%|████████  | 8101/10000 [28:54<06:46,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-140.78423437267887\n",
      "iter=8100\tepsilon=0.050\n",
      "Current score(mean over 3) = -162.334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 8199/10000 [29:16<06:25,  4.67it/s][2017-11-04 22:13:27,526] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:13:27,530] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-140.20944921390296\n",
      "Episode finished after 1000 timesteps with reward=-180.6697749879496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:13:36,991] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 82%|████████▏ | 8200/10000 [29:26<06:27,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-155.21522479209077\n",
      "iter=8200\tepsilon=0.050\n",
      "Current score(mean over 3) = -158.698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 8299/10000 [29:46<06:06,  4.64it/s][2017-11-04 22:13:57,405] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:13:57,410] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-141.08944638248423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:14:04,836] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 83%|████████▎ | 8301/10000 [29:54<06:07,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-156.6777153606147\n",
      "Episode finished after 1000 timesteps with reward=-155.7781546864284\n",
      "iter=8300\tepsilon=0.050\n",
      "Current score(mean over 3) = -151.182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 8399/10000 [30:11<05:45,  4.64it/s][2017-11-04 22:14:22,085] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:14:22,089] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-115.64817445648781\n",
      "Episode finished after 1000 timesteps with reward=-143.9592433301951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:14:29,728] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 84%|████████▍ | 8401/10000 [30:19<05:46,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-175.59268483461685\n",
      "iter=8400\tepsilon=0.050\n",
      "Current score(mean over 3) = -145.067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 8499/10000 [30:40<05:25,  4.62it/s][2017-11-04 22:14:50,907] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:14:50,915] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-113.18881625960087\n",
      "Episode finished after 1000 timesteps with reward=-104.38610344302461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:15:07,178] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 85%|████████▌ | 8500/10000 [30:56<05:27,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-159.70402395254217\n",
      "iter=8500\tepsilon=0.050\n",
      "Current score(mean over 3) = -125.760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 8599/10000 [31:33<05:08,  4.54it/s][2017-11-04 22:15:44,819] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:15:44,826] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-132.04603668375842\n",
      "Episode finished after 1000 timesteps with reward=-137.32294025783025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:15:54,837] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 86%|████████▌ | 8600/10000 [31:44<05:10,  4.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-129.7010596858205\n",
      "iter=8600\tepsilon=0.050\n",
      "Current score(mean over 3) = -133.023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 8699/10000 [32:06<04:48,  4.52it/s][2017-11-04 22:16:17,021] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:16:17,027] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-143.57779092555862\n",
      "Episode finished after 1000 timesteps with reward=-129.59907129563538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:16:25,492] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 87%|████████▋ | 8700/10000 [32:15<04:49,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-137.24534955139157\n",
      "iter=8700\tepsilon=0.050\n",
      "Current score(mean over 3) = -136.807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 8799/10000 [32:34<04:26,  4.50it/s][2017-11-04 22:16:44,791] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:16:44,795] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-148.12496161760606\n",
      "Episode finished after 1000 timesteps with reward=-176.4090689562356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:16:56,556] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 88%|████████▊ | 8800/10000 [32:46<04:28,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-191.07369456248986\n",
      "iter=8800\tepsilon=0.050\n",
      "Current score(mean over 3) = -171.869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 8899/10000 [33:03<04:05,  4.49it/s][2017-11-04 22:17:14,528] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:17:14,533] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-119.05894557746541\n",
      "Episode finished after 1000 timesteps with reward=-108.83565084129803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:17:22,393] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 89%|████████▉ | 8900/10000 [33:11<04:06,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-155.03886742378089\n",
      "iter=8900\tepsilon=0.050\n",
      "Current score(mean over 3) = -127.644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 8999/10000 [33:33<03:43,  4.47it/s][2017-11-04 22:17:43,769] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:17:43,780] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-106.89885001454655\n",
      "Episode finished after 1000 timesteps with reward=-144.16978031596335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:17:53,727] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 90%|█████████ | 9000/10000 [33:43<03:44,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-137.160532861433\n",
      "iter=9000\tepsilon=0.050\n",
      "Current score(mean over 3) = -129.410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 9099/10000 [34:01<03:22,  4.46it/s][2017-11-04 22:18:12,521] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:18:12,526] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-124.3991554449418\n",
      "Episode finished after 1000 timesteps with reward=-117.57935759853508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:18:22,273] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 91%|█████████ | 9101/10000 [34:12<03:22,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-146.95102307278094\n",
      "iter=9100\tepsilon=0.050\n",
      "Current score(mean over 3) = -129.643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 9199/10000 [34:31<03:00,  4.44it/s][2017-11-04 22:18:42,303] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:18:42,308] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-92.35041062720975\n",
      "Episode finished after 1000 timesteps with reward=-167.4312346863879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:18:52,943] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 92%|█████████▏| 9200/10000 [34:42<03:01,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-136.4128936657547\n",
      "iter=9200\tepsilon=0.050\n",
      "Current score(mean over 3) = -132.065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 9299/10000 [34:59<02:38,  4.43it/s][2017-11-04 22:19:10,432] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:19:10,437] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-119.14032356476167\n",
      "Episode finished after 1000 timesteps with reward=-151.45425562907752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:19:16,796] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 93%|█████████▎| 9301/10000 [35:06<02:38,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-135.48203831951318\n",
      "iter=9300\tepsilon=0.050\n",
      "Current score(mean over 3) = -135.359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 9399/10000 [35:27<02:16,  4.42it/s][2017-11-04 22:19:38,239] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:19:38,245] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-169.57913091121347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:19:44,739] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 94%|█████████▍| 9400/10000 [35:34<02:16,  4.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-119.53434270113836\n",
      "Episode finished after 107 timesteps with reward=-162.8217852649354\n",
      "iter=9400\tepsilon=0.050\n",
      "Current score(mean over 3) = -150.645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 9499/10000 [35:53<01:53,  4.41it/s][2017-11-04 22:20:03,931] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:20:03,936] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-125.09088969939035\n",
      "Episode finished after 1000 timesteps with reward=-129.73332876173623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:20:14,908] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 95%|█████████▌| 9501/10000 [36:04<01:53,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-123.07254151700901\n",
      "iter=9500\tepsilon=0.050\n",
      "Current score(mean over 3) = -125.966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 9599/10000 [36:25<01:31,  4.39it/s][2017-11-04 22:20:35,926] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:20:35,931] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-148.82870249280757\n",
      "Episode finished after 1000 timesteps with reward=-175.63494528021772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:20:46,044] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 96%|█████████▌| 9600/10000 [36:35<01:31,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-128.6685495020235\n",
      "iter=9600\tepsilon=0.050\n",
      "Current score(mean over 3) = -151.044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 9699/10000 [36:55<01:08,  4.38it/s][2017-11-04 22:21:06,118] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:21:06,123] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-156.9497200615122\n",
      "Episode finished after 1000 timesteps with reward=-117.73244026403515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:21:17,000] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 97%|█████████▋| 9700/10000 [37:06<01:08,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-135.7868683733784\n",
      "iter=9700\tepsilon=0.050\n",
      "Current score(mean over 3) = -136.823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 9799/10000 [37:27<00:46,  4.36it/s][2017-11-04 22:21:37,937] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:21:37,942] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-104.37676475071025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:21:46,529] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 98%|█████████▊| 9800/10000 [37:36<00:46,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-119.91824628440006\n",
      "Episode finished after 1000 timesteps with reward=-106.4835603866273\n",
      "iter=9800\tepsilon=0.050\n",
      "Current score(mean over 3) = -110.260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 9899/10000 [37:56<00:23,  4.35it/s][2017-11-04 22:22:06,919] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:22:06,923] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-92.07560845548532\n",
      "Episode finished after 1000 timesteps with reward=-120.86201435960552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:22:16,674] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 99%|█████████▉| 9901/10000 [38:06<00:22,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-148.40957440553981\n",
      "iter=9900\tepsilon=0.050\n",
      "Current score(mean over 3) = -120.449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 9999/10000 [38:28<00:00,  4.33it/s][2017-11-04 22:22:39,609] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:22:39,614] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-158.4430599043674\n",
      "Episode finished after 1000 timesteps with reward=-160.48080598163727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:22:52,440] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      "100%|██████████| 10000/10000 [38:42<00:00,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-115.76289772445782\n",
      "iter=10000\tepsilon=0.050\n",
      "Current score(mean over 3) = -144.896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "for i in trange(10000):    \n",
    "    \n",
    "    #play\n",
    "    for _ in range(5):\n",
    "        pool.update(SEQ_LENGTH,append=True)\n",
    "    \n",
    "    #train\n",
    "    train_step()\n",
    "    \n",
    "    #update epsilon\n",
    "    epsilon = 0.05 + 0.95*np.exp(-epoch_counter/1000.)\n",
    "    action_layer.epsilon.set_value(np.float32(epsilon))\n",
    "    \n",
    "    #play a few games for evaluation\n",
    "    if epoch_counter%100==0:\n",
    "        rewards[epoch_counter] = np.mean(pool.evaluate(n_games=3,record_video=False))\n",
    "        print(\"iter=%i\\tepsilon=%.3f\"%(epoch_counter,action_layer.epsilon.get_value(),))\n",
    "        print(\"Current score(mean over %i) = %.3f\"%(3,np.mean(rewards[epoch_counter])))\n",
    "    \n",
    "        if rewards[epoch_counter] >= target_score:\n",
    "            print(\"You win!\")\n",
    "            break\n",
    "\n",
    "    \n",
    "    epoch_counter  +=1\n",
    "\n",
    "    \n",
    "# Time to drink some coffee!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import ewma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nimloth/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:2: FutureWarning: pd.ewm_mean is deprecated for ndarrays and will be removed in a future version\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f378979e940>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD8CAYAAACVZ8iyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDQZKKaXQYKCUUgoNBkoppYD/D/hEJNTBSEERAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f378af897f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iters,session_rewards=zip(*sorted(rewards.items(),key=lambda x:x[0]))\n",
    "plt.plot(iters, ewma(np.array(session_rewards),span=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 99/10000 [00:30<50:57,  3.24it/s][2017-11-04 22:44:30,908] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:44:30,936] Clearing 6 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-143.38933353745315\n",
      "Episode finished after 1000 timesteps with reward=-138.43861163191923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:44:43,958] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      "  1%|          | 100/10000 [00:43<1:12:21,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-176.80691272795826\n",
      "iter=10100\tepsilon=0.050\n",
      "Current score(mean over 3) = -152.878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 199/10000 [01:13<59:59,  2.72it/s]  [2017-11-04 22:45:13,523] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:45:13,550] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-122.54527794899725\n",
      "Episode finished after 1000 timesteps with reward=-110.35189020002616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:45:30,717] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      "  2%|▏         | 200/10000 [01:30<1:13:59,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-120.70034354861777\n",
      "iter=10200\tepsilon=0.050\n",
      "Current score(mean over 3) = -117.866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 299/10000 [02:03<1:06:41,  2.42it/s][2017-11-04 22:46:03,630] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:46:03,655] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-143.4870926691052\n",
      "Episode finished after 1000 timesteps with reward=-137.44431582705542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:46:22,610] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      "  3%|▎         | 300/10000 [02:22<1:16:47,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-157.00400590786316\n",
      "iter=10300\tepsilon=0.050\n",
      "Current score(mean over 3) = -145.978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 399/10000 [02:59<1:12:04,  2.22it/s][2017-11-04 22:47:00,711] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:47:00,727] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-135.96082726926332\n",
      "Episode finished after 1000 timesteps with reward=-134.49837551388427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:47:13,405] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      "  4%|▍         | 400/10000 [03:13<1:17:19,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-119.8742637854795\n",
      "iter=10400\tepsilon=0.050\n",
      "Current score(mean over 3) = -130.111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 499/10000 [03:48<1:12:28,  2.18it/s][2017-11-04 22:47:48,703] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:47:48,737] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-168.9414268503587\n",
      "Episode finished after 1000 timesteps with reward=-128.8572971388957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:48:02,270] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      "  5%|▌         | 500/10000 [04:02<1:16:41,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-174.7741169204189\n",
      "iter=10500\tepsilon=0.050\n",
      "Current score(mean over 3) = -157.524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 599/10000 [04:34<1:11:46,  2.18it/s][2017-11-04 22:48:34,969] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:48:34,989] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-158.59755244329054\n",
      "Episode finished after 1000 timesteps with reward=-133.35252136294193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:48:48,564] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      "  6%|▌         | 600/10000 [04:48<1:15:19,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-142.01482241268218\n",
      "iter=10600\tepsilon=0.050\n",
      "Current score(mean over 3) = -144.655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 699/10000 [05:15<1:09:59,  2.21it/s][2017-11-04 22:49:15,896] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:49:15,904] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-131.3765337861477\n",
      "Episode finished after 1000 timesteps with reward=-177.8009969057576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:49:32,706] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      "  7%|▋         | 700/10000 [05:32<1:13:38,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-151.3847123909276\n",
      "iter=10700\tepsilon=0.050\n",
      "Current score(mean over 3) = -153.521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 799/10000 [05:57<1:08:38,  2.23it/s][2017-11-04 22:49:58,153] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:49:58,159] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-132.29576522592174\n",
      "Episode finished after 1000 timesteps with reward=-134.04122487880366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:50:13,573] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      "  8%|▊         | 800/10000 [06:13<1:11:34,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-145.8601981492924\n",
      "iter=10800\tepsilon=0.050\n",
      "Current score(mean over 3) = -137.399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 899/10000 [06:37<1:07:08,  2.26it/s][2017-11-04 22:50:38,301] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:50:38,332] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-130.76538608018137\n",
      "Episode finished after 1000 timesteps with reward=-159.97671864025617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:50:53,070] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      "  9%|▉         | 900/10000 [06:52<1:09:35,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-162.63683024361808\n",
      "iter=10900\tepsilon=0.050\n",
      "Current score(mean over 3) = -151.126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 999/10000 [07:16<1:05:33,  2.29it/s][2017-11-04 22:51:16,946] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:51:16,951] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-126.46285551855541\n",
      "Episode finished after 1000 timesteps with reward=-163.58956110463976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:51:26,833] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 10%|█         | 1000/10000 [07:26<1:07:00,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-142.27458985478654\n",
      "iter=11000\tepsilon=0.050\n",
      "Current score(mean over 3) = -144.109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1099/10000 [07:53<1:03:50,  2.32it/s][2017-11-04 22:51:53,306] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:51:53,314] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-120.21620507312637\n",
      "Episode finished after 1000 timesteps with reward=-171.34767382909425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:52:07,425] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 11%|█         | 1101/10000 [08:07<1:05:40,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-181.0773927651\n",
      "iter=11100\tepsilon=0.050\n",
      "Current score(mean over 3) = -157.547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1199/10000 [08:40<1:03:41,  2.30it/s][2017-11-04 22:52:41,390] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:52:41,398] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-108.1130135860529\n",
      "Episode finished after 1000 timesteps with reward=-107.32278218234553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:52:52,941] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 12%|█▏        | 1200/10000 [08:52<1:05:07,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-126.86700853262397\n",
      "iter=11200\tepsilon=0.050\n",
      "Current score(mean over 3) = -114.101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 1299/10000 [09:24<1:03:01,  2.30it/s][2017-11-04 22:53:24,874] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:53:24,896] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-170.7875185789915\n",
      "Episode finished after 1000 timesteps with reward=-148.39127873165293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:53:36,258] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 13%|█▎        | 1300/10000 [09:36<1:04:15,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-137.21769855241976\n",
      "iter=11300\tepsilon=0.050\n",
      "Current score(mean over 3) = -152.132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1399/10000 [10:06<1:02:07,  2.31it/s][2017-11-04 22:54:06,751] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:54:06,773] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-103.31625019359883\n",
      "Episode finished after 1000 timesteps with reward=-133.5181572581226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:54:21,489] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 14%|█▍        | 1400/10000 [10:21<1:03:37,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-152.59660429119802\n",
      "iter=11400\tepsilon=0.050\n",
      "Current score(mean over 3) = -129.810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 1499/10000 [10:57<1:02:10,  2.28it/s][2017-11-04 22:54:58,167] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:54:58,189] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-149.78275733249356\n",
      "Episode finished after 1000 timesteps with reward=-114.19776538464573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:55:10,868] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 15%|█▌        | 1501/10000 [11:10<1:03:18,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-159.0108704748387\n",
      "iter=11500\tepsilon=0.050\n",
      "Current score(mean over 3) = -140.997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 1599/10000 [11:39<1:01:14,  2.29it/s][2017-11-04 22:55:39,795] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:55:39,802] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-165.05863180292698\n",
      "Episode finished after 1000 timesteps with reward=-128.69998256942728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:55:55,089] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 16%|█▌        | 1600/10000 [11:54<1:02:33,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-164.29428434621946\n",
      "iter=11600\tepsilon=0.050\n",
      "Current score(mean over 3) = -152.684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1699/10000 [12:20<1:00:18,  2.29it/s][2017-11-04 22:56:20,945] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:56:20,972] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-148.57380136747722\n",
      "Episode finished after 1000 timesteps with reward=-129.08906247509955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:56:32,349] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 17%|█▋        | 1700/10000 [12:32<1:01:12,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-114.1758207783207\n",
      "iter=11700\tepsilon=0.050\n",
      "Current score(mean over 3) = -130.613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 1799/10000 [12:58<59:10,  2.31it/s][2017-11-04 22:56:59,328] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:56:59,348] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-175.08774700464852\n",
      "Episode finished after 1000 timesteps with reward=-189.74314788448496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:57:13,301] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 18%|█▊        | 1800/10000 [13:13<1:00:13,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-154.32411645223635\n",
      "iter=11800\tepsilon=0.050\n",
      "Current score(mean over 3) = -173.052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 1899/10000 [13:39<58:16,  2.32it/s][2017-11-04 22:57:39,884] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:57:39,909] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-160.25589044017784\n",
      "Episode finished after 1000 timesteps with reward=-147.56004731532278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:57:55,623] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 19%|█▉        | 1900/10000 [13:55<59:21,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-146.98072139219386\n",
      "iter=11900\tepsilon=0.050\n",
      "Current score(mean over 3) = -151.599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 1999/10000 [14:23<57:34,  2.32it/s][2017-11-04 22:58:23,588] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:58:23,613] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-154.99252799813993\n",
      "Episode finished after 1000 timesteps with reward=-158.97636470669218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:58:35,420] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 20%|██        | 2000/10000 [14:35<58:21,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-126.07137100275635\n",
      "iter=12000\tepsilon=0.050\n",
      "Current score(mean over 3) = -146.680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 2099/10000 [15:05<56:47,  2.32it/s][2017-11-04 22:59:05,571] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:59:05,608] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-158.77616328261936\n",
      "Episode finished after 1000 timesteps with reward=-180.17410846907106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:59:18,899] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 21%|██        | 2100/10000 [15:18<57:36,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-187.9299066398737\n",
      "iter=12100\tepsilon=0.050\n",
      "Current score(mean over 3) = -175.627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2199/10000 [15:45<55:53,  2.33it/s][2017-11-04 22:59:45,870] Making new env: LunarLander-v2\n",
      "[2017-11-04 22:59:45,878] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-109.20959952557311\n",
      "Episode finished after 1000 timesteps with reward=-121.4488528932732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:59:58,240] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 22%|██▏       | 2200/10000 [15:58<56:37,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-139.9675221477822\n",
      "iter=12200\tepsilon=0.050\n",
      "Current score(mean over 3) = -123.542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 2299/10000 [16:31<55:22,  2.32it/s][2017-11-04 23:00:32,322] Making new env: LunarLander-v2\n",
      "[2017-11-04 23:00:32,348] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-155.96453631837397\n",
      "Episode finished after 1000 timesteps with reward=-97.08764090087375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:00:42,479] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 23%|██▎       | 2301/10000 [16:42<55:54,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-147.01768992521474\n",
      "iter=12300\tepsilon=0.050\n",
      "Current score(mean over 3) = -133.357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 2399/10000 [17:08<54:19,  2.33it/s][2017-11-04 23:01:09,227] Making new env: LunarLander-v2\n",
      "[2017-11-04 23:01:09,235] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-112.09806684774982\n",
      "Episode finished after 1000 timesteps with reward=-157.42308671634922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:01:23,574] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 24%|██▍       | 2400/10000 [17:23<55:04,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-160.7109469629108\n",
      "iter=12400\tepsilon=0.050\n",
      "Current score(mean over 3) = -143.411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 2499/10000 [17:51<53:35,  2.33it/s][2017-11-04 23:01:51,940] Making new env: LunarLander-v2\n",
      "[2017-11-04 23:01:51,970] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 142 timesteps with reward=-123.41464373162978\n",
      "Episode finished after 1000 timesteps with reward=-167.4300554102939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:01:59,501] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 25%|██▌       | 2501/10000 [17:59<53:56,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-142.32989343200407\n",
      "iter=12500\tepsilon=0.050\n",
      "Current score(mean over 3) = -144.392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 2599/10000 [18:26<52:31,  2.35it/s][2017-11-04 23:02:27,082] Making new env: LunarLander-v2\n",
      "[2017-11-04 23:02:27,104] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-155.95254651564352\n",
      "Episode finished after 1000 timesteps with reward=-138.91204357601924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:02:41,186] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 26%|██▌       | 2600/10000 [18:41<53:10,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-162.68115740746308\n",
      "iter=12600\tepsilon=0.050\n",
      "Current score(mean over 3) = -152.515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 2699/10000 [19:15<52:04,  2.34it/s][2017-11-04 23:03:15,534] Making new env: LunarLander-v2\n",
      "[2017-11-04 23:03:15,561] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-110.94304772562894\n",
      "Episode finished after 1000 timesteps with reward=-125.67507567429473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:03:32,249] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 27%|██▋       | 2700/10000 [19:32<52:49,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-172.731404716755\n",
      "iter=12700\tepsilon=0.050\n",
      "Current score(mean over 3) = -136.450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 2799/10000 [19:59<51:26,  2.33it/s][2017-11-04 23:03:59,935] Making new env: LunarLander-v2\n",
      "[2017-11-04 23:03:59,945] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-175.95074158225157\n",
      "Episode finished after 1000 timesteps with reward=-117.81373322618667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:04:17,057] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 28%|██▊       | 2801/10000 [20:17<52:08,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-126.50898008636992\n",
      "iter=12800\tepsilon=0.050\n",
      "Current score(mean over 3) = -140.091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 2899/10000 [20:48<50:59,  2.32it/s][2017-11-04 23:04:49,407] Making new env: LunarLander-v2\n",
      "[2017-11-04 23:04:49,418] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-166.44439165887263\n",
      "Episode finished after 1000 timesteps with reward=-127.57930299302267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:05:09,187] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 29%|██▉       | 2900/10000 [21:09<51:47,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-137.03827059246242\n",
      "iter=12900\tepsilon=0.050\n",
      "Current score(mean over 3) = -143.687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 2999/10000 [21:47<50:52,  2.29it/s][2017-11-04 23:05:48,077] Making new env: LunarLander-v2\n",
      "[2017-11-04 23:05:48,087] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-102.66528566349997\n",
      "Episode finished after 1000 timesteps with reward=-160.60209058737325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:06:09,152] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 30%|███       | 3000/10000 [22:09<51:41,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-137.01185247422342\n",
      "iter=13000\tepsilon=0.050\n",
      "Current score(mean over 3) = -133.426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 3099/10000 [22:47<50:44,  2.27it/s][2017-11-04 23:06:47,646] Making new env: LunarLander-v2\n",
      "[2017-11-04 23:06:47,673] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-151.6476734023472\n",
      "Episode finished after 1000 timesteps with reward=-154.38546254582815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:07:06,618] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 31%|███       | 3100/10000 [23:06<51:26,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-158.456697982927\n",
      "iter=13100\tepsilon=0.050\n",
      "Current score(mean over 3) = -154.830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 3199/10000 [23:39<50:16,  2.25it/s][2017-11-04 23:07:39,288] Making new env: LunarLander-v2\n",
      "[2017-11-04 23:07:39,296] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-111.07203594518633\n",
      "Episode finished after 94 timesteps with reward=-203.55678990401643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:07:50,601] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 32%|███▏      | 3201/10000 [23:50<50:38,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-136.69997105287732\n",
      "iter=13200\tepsilon=0.050\n",
      "Current score(mean over 3) = -150.443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3299/10000 [24:21<49:28,  2.26it/s][2017-11-04 23:08:21,692] Making new env: LunarLander-v2\n",
      "[2017-11-04 23:08:21,713] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-105.22021215258621\n",
      "Episode finished after 1000 timesteps with reward=-107.98598233427118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:08:38,487] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 33%|███▎      | 3301/10000 [24:38<50:00,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-147.01176210633054\n",
      "iter=13300\tepsilon=0.050\n",
      "Current score(mean over 3) = -120.073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 3399/10000 [25:11<48:54,  2.25it/s][2017-11-04 23:09:11,405] Making new env: LunarLander-v2\n",
      "[2017-11-04 23:09:11,415] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-132.25928773581208\n",
      "Episode finished after 1000 timesteps with reward=-140.5723781310179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:09:24,697] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 34%|███▍      | 3400/10000 [25:24<49:19,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-128.50016137553604\n",
      "iter=13400\tepsilon=0.050\n",
      "Current score(mean over 3) = -133.777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 3499/10000 [25:52<48:04,  2.25it/s][2017-11-04 23:09:53,273] Making new env: LunarLander-v2\n",
      "[2017-11-04 23:09:53,298] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-159.59437745660088\n",
      "Episode finished after 1000 timesteps with reward=-113.54075556233461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:10:09,257] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 35%|███▌      | 3500/10000 [26:09<48:34,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-120.0637737358601\n",
      "iter=13500\tepsilon=0.050\n",
      "Current score(mean over 3) = -131.066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 3599/10000 [26:41<47:28,  2.25it/s][2017-11-04 23:10:41,765] Making new env: LunarLander-v2\n",
      "[2017-11-04 23:10:41,784] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 148 timesteps with reward=-141.6966731613448\n",
      "Episode finished after 1000 timesteps with reward=-132.49171193367096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:10:51,553] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 36%|███▌      | 3601/10000 [26:51<47:43,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-130.52400298098144\n",
      "iter=13600\tepsilon=0.050\n",
      "Current score(mean over 3) = -134.904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 3699/10000 [27:18<46:31,  2.26it/s][2017-11-04 23:11:19,225] Making new env: LunarLander-v2\n",
      "[2017-11-04 23:11:19,232] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-137.3130232996279\n",
      "Episode finished after 1000 timesteps with reward=-131.63361536160892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:11:32,391] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 37%|███▋      | 3700/10000 [27:32<46:53,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-134.0080955871241\n",
      "iter=13700\tepsilon=0.050\n",
      "Current score(mean over 3) = -134.318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3799/10000 [28:00<45:43,  2.26it/s][2017-11-04 23:12:01,062] Making new env: LunarLander-v2\n",
      "[2017-11-04 23:12:01,085] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-132.54219423421873\n",
      "Episode finished after 1000 timesteps with reward=-151.05652784706015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:12:13,807] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 38%|███▊      | 3800/10000 [28:13<46:03,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-183.908779550537\n",
      "iter=13800\tepsilon=0.050\n",
      "Current score(mean over 3) = -155.836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 3899/10000 [28:38<44:49,  2.27it/s][2017-11-04 23:12:39,240] Making new env: LunarLander-v2\n",
      "[2017-11-04 23:12:39,248] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-153.23723847328384\n",
      "Episode finished after 1000 timesteps with reward=-145.68321603163133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:12:53,265] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 39%|███▉      | 3900/10000 [28:53<45:10,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-164.58504355954813\n",
      "iter=13900\tepsilon=0.050\n",
      "Current score(mean over 3) = -154.502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 3999/10000 [29:23<44:06,  2.27it/s][2017-11-04 23:13:24,161] Making new env: LunarLander-v2\n",
      "[2017-11-04 23:13:24,181] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-161.50489643510767\n",
      "Episode finished after 126 timesteps with reward=-170.9988837063923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:13:37,442] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 40%|████      | 4001/10000 [29:37<44:25,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-144.19881254906613\n",
      "iter=14000\tepsilon=0.050\n",
      "Current score(mean over 3) = -158.901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 4099/10000 [30:06<43:20,  2.27it/s][2017-11-04 23:14:07,070] Making new env: LunarLander-v2\n",
      "[2017-11-04 23:14:07,091] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-110.45803006684409\n",
      "Episode finished after 1000 timesteps with reward=-131.5872783292744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:14:25,408] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 41%|████      | 4100/10000 [30:25<43:46,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-124.60914497327026\n",
      "iter=14100\tepsilon=0.050\n",
      "Current score(mean over 3) = -122.218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 4199/10000 [30:53<42:40,  2.27it/s][2017-11-04 23:14:53,951] Making new env: LunarLander-v2\n",
      "[2017-11-04 23:14:53,973] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-151.8585737610222\n",
      "Episode finished after 1000 timesteps with reward=-97.81262675363234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:15:05,780] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 42%|████▏     | 4200/10000 [31:05<42:56,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-202.7144470074639\n",
      "iter=14200\tepsilon=0.050\n",
      "Current score(mean over 3) = -150.795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 4299/10000 [31:35<41:53,  2.27it/s][2017-11-04 23:15:35,799] Making new env: LunarLander-v2\n",
      "[2017-11-04 23:15:35,806] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 133 timesteps with reward=-145.8279109973744\n",
      "Episode finished after 1000 timesteps with reward=-146.90383535826743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:15:45,561] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 43%|████▎     | 4300/10000 [31:45<42:05,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-135.32683616775773\n",
      "iter=14300\tepsilon=0.050\n",
      "Current score(mean over 3) = -142.686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4399/10000 [32:12<41:00,  2.28it/s][2017-11-04 23:16:12,472] Making new env: LunarLander-v2\n",
      "[2017-11-04 23:16:12,480] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-151.87229705604446\n",
      "Episode finished after 1000 timesteps with reward=-153.26270003754206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:16:27,112] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 44%|████▍     | 4400/10000 [32:27<41:18,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-144.40156365438153\n",
      "iter=14400\tepsilon=0.050\n",
      "Current score(mean over 3) = -149.846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 4499/10000 [32:55<40:15,  2.28it/s][2017-11-04 23:16:55,628] Making new env: LunarLander-v2\n",
      "[2017-11-04 23:16:55,634] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-103.96832785705523\n",
      "Episode finished after 1000 timesteps with reward=-178.6222614867868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:17:07,203] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 45%|████▌     | 4500/10000 [33:07<40:28,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-135.22216010766078\n",
      "iter=14500\tepsilon=0.050\n",
      "Current score(mean over 3) = -139.271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 4599/10000 [33:33<39:24,  2.28it/s][2017-11-04 23:17:34,024] Making new env: LunarLander-v2\n",
      "[2017-11-04 23:17:34,045] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-178.1187786116958\n",
      "Episode finished after 1000 timesteps with reward=-190.34568485041487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:17:47,449] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 46%|████▌     | 4600/10000 [33:47<39:39,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-167.12092074069514\n",
      "iter=14600\tepsilon=0.050\n",
      "Current score(mean over 3) = -178.528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 4699/10000 [34:14<38:37,  2.29it/s][2017-11-04 23:18:14,558] Making new env: LunarLander-v2\n",
      "[2017-11-04 23:18:14,588] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-157.79684292297944\n",
      "Episode finished after 1000 timesteps with reward=-185.04146392470375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:18:30,644] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 47%|████▋     | 4701/10000 [34:30<38:54,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-164.51109365946743\n",
      "iter=14700\tepsilon=0.050\n",
      "Current score(mean over 3) = -169.116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 4799/10000 [34:56<37:52,  2.29it/s][2017-11-04 23:18:57,039] Making new env: LunarLander-v2\n",
      "[2017-11-04 23:18:57,061] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-170.61360344251844\n",
      "Episode finished after 1000 timesteps with reward=-138.22242217163154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:19:08,513] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 48%|████▊     | 4800/10000 [35:08<38:04,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-170.02929373524591\n",
      "iter=14800\tepsilon=0.050\n",
      "Current score(mean over 3) = -159.622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 4899/10000 [35:40<37:08,  2.29it/s][2017-11-04 23:19:41,222] Making new env: LunarLander-v2\n",
      "[2017-11-04 23:19:41,244] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-153.78992379243059\n",
      "Episode finished after 1000 timesteps with reward=-102.91533632582596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:19:53,977] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 49%|████▉     | 4900/10000 [35:53<37:21,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-163.2891164864576\n",
      "iter=14900\tepsilon=0.050\n",
      "Current score(mean over 3) = -139.998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 4999/10000 [36:24<36:25,  2.29it/s][2017-11-04 23:20:24,773] Making new env: LunarLander-v2\n",
      "[2017-11-04 23:20:24,793] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 186 timesteps with reward=-134.34286990021664\n",
      "Episode finished after 1000 timesteps with reward=-131.089445553462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:20:33,425] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 50%|█████     | 5000/10000 [36:33<36:33,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-190.66893384726134\n",
      "iter=15000\tepsilon=0.050\n",
      "Current score(mean over 3) = -152.034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 5099/10000 [37:01<35:35,  2.30it/s][2017-11-04 23:21:02,214] Making new env: LunarLander-v2\n",
      "[2017-11-04 23:21:02,237] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-159.66641455242114\n",
      "Episode finished after 1000 timesteps with reward=-162.93202398795225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:21:15,966] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 51%|█████     | 5100/10000 [37:15<35:48,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-147.65482475438543\n",
      "iter=15100\tepsilon=0.050\n",
      "Current score(mean over 3) = -156.751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 5199/10000 [37:46<34:53,  2.29it/s][2017-11-04 23:21:47,304] Making new env: LunarLander-v2\n",
      "[2017-11-04 23:21:47,311] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-109.81063689187934\n",
      "Episode finished after 1000 timesteps with reward=-140.4900134069601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:22:03,885] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 52%|█████▏    | 5200/10000 [38:03<35:08,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-195.11112938660574\n",
      "iter=15200\tepsilon=0.050\n",
      "Current score(mean over 3) = -148.471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 5299/10000 [38:32<34:11,  2.29it/s][2017-11-04 23:22:33,183] Making new env: LunarLander-v2\n",
      "[2017-11-04 23:22:33,190] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-154.15372578681882\n",
      "Episode finished after 1000 timesteps with reward=-160.69191917744973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:22:45,175] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 53%|█████▎    | 5300/10000 [38:45<34:21,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-162.7080475679551\n",
      "iter=15300\tepsilon=0.050\n",
      "Current score(mean over 3) = -159.185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 5399/10000 [39:15<33:26,  2.29it/s][2017-11-04 23:23:15,491] Making new env: LunarLander-v2\n",
      "[2017-11-04 23:23:15,510] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-158.84656160476894\n",
      "Episode finished after 1000 timesteps with reward=-111.30752930679938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:23:24,942] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 54%|█████▍    | 5400/10000 [39:24<33:34,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 139 timesteps with reward=-147.38212954290617\n",
      "iter=15400\tepsilon=0.050\n",
      "Current score(mean over 3) = -139.179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 5499/10000 [39:53<32:39,  2.30it/s][2017-11-04 23:23:53,915] Making new env: LunarLander-v2\n",
      "[2017-11-04 23:23:53,923] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 205 timesteps with reward=-171.63555313132272\n",
      "Episode finished after 1000 timesteps with reward=-180.35728302416345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:24:04,871] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 55%|█████▌    | 5500/10000 [40:04<32:47,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-86.68913736965493\n",
      "iter=15500\tepsilon=0.050\n",
      "Current score(mean over 3) = -146.227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 5599/10000 [40:38<31:57,  2.30it/s][2017-11-04 23:24:39,245] Making new env: LunarLander-v2\n",
      "[2017-11-04 23:24:39,253] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-165.71438314152024\n",
      "Episode finished after 224 timesteps with reward=-152.29770835964595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:24:47,781] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 56%|█████▌    | 5600/10000 [40:47<32:03,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-147.48794045151936\n",
      "iter=15600\tepsilon=0.050\n",
      "Current score(mean over 3) = -155.167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 5699/10000 [41:18<31:10,  2.30it/s][2017-11-04 23:25:18,900] Making new env: LunarLander-v2\n",
      "[2017-11-04 23:25:18,921] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-92.49755007402679\n",
      "Episode finished after 1000 timesteps with reward=-139.1104767596936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:25:32,622] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 57%|█████▋    | 5700/10000 [41:32<31:20,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-136.7302655924316\n",
      "iter=15700\tepsilon=0.050\n",
      "Current score(mean over 3) = -122.779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 5799/10000 [42:03<30:27,  2.30it/s][2017-11-04 23:26:03,454] Making new env: LunarLander-v2\n",
      "[2017-11-04 23:26:03,475] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-134.6405081690015\n",
      "Episode finished after 1000 timesteps with reward=-157.16781752705154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:26:13,974] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 58%|█████▊    | 5800/10000 [42:13<30:34,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-143.91438342893662\n",
      "iter=15800\tepsilon=0.050\n",
      "Current score(mean over 3) = -145.241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 5899/10000 [42:40<29:39,  2.30it/s][2017-11-04 23:26:40,485] Making new env: LunarLander-v2\n",
      "[2017-11-04 23:26:40,513] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-146.76662547686442\n",
      "Episode finished after 1000 timesteps with reward=-125.75684606637492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:26:57,329] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/nimloth/coding/7sem/machine_learning_7sem/hw5/records')\n",
      " 59%|█████▉    | 5900/10000 [42:57<29:50,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-166.51547548143066\n",
      "iter=15900\tepsilon=0.050\n",
      "Current score(mean over 3) = -146.346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 5999/10000 [43:27<28:59,  2.30it/s][2017-11-04 23:27:28,083] Making new env: LunarLander-v2\n",
      "[2017-11-04 23:27:28,093] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-144.2501556674284\n",
      "Episode finished after 1000 timesteps with reward=-170.40772624635042\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-fffb4ae71958>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#play a few games for evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch_counter\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mrewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch_counter\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_games\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrecord_video\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iter=%i\\tepsilon=%.3f\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_counter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maction_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Current score(mean over %i) = %.3f\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch_counter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nimloth/anaconda3/lib/python3.5/site-packages/agentnet/experiments/openai_gym/pool.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, n_games, save_path, use_monitor, record_video, verbose, t_max)\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_observation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mprev_memories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m                 \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_memories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nimloth/anaconda3/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nimloth/anaconda3/lib/python3.5/site-packages/theano/gof/op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    870\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m                     \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nimloth/anaconda3/lib/python3.5/site-packages/theano/tensor/raw_random.py\u001b[0m in \u001b[0;36mperform\u001b[0;34m(self, node, inputs, out_)\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mrout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexec_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         if (not isinstance(rval, numpy.ndarray) or\n\u001b[1;32m    264\u001b[0m                 str(rval.dtype) != node.outputs[1].type.dtype):\n",
      "\u001b[0;32m/home/nimloth/anaconda3/lib/python3.5/site-packages/theano/tensor/raw_random.py\u001b[0m in \u001b[0;36mchoice_helper\u001b[0;34m(random_state, a, replace, p, size)\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'p.ndim (%i) must be 1'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m     \u001b[0mreplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "for i in trange(10000):    \n",
    "    \n",
    "    #play\n",
    "    for _ in range(5):\n",
    "        pool.update(SEQ_LENGTH,append=True)\n",
    "    \n",
    "    #train\n",
    "    train_step()\n",
    "    \n",
    "    #update epsilon\n",
    "    epsilon = 0.05 + 0.95*np.exp(-epoch_counter/1000.)\n",
    "    action_layer.epsilon.set_value(np.float32(epsilon))\n",
    "    \n",
    "    #play a few games for evaluation\n",
    "    if epoch_counter%100==0:\n",
    "        rewards[epoch_counter] = np.mean(pool.evaluate(n_games=3,record_video=False))\n",
    "        print(\"iter=%i\\tepsilon=%.3f\"%(epoch_counter,action_layer.epsilon.get_value(),))\n",
    "        print(\"Current score(mean over %i) = %.3f\"%(3,np.mean(rewards[epoch_counter])))\n",
    "    \n",
    "        if rewards[epoch_counter] >= target_score:\n",
    "            print(\"You win!\")\n",
    "            break\n",
    "\n",
    "    \n",
    "    epoch_counter  +=1\n",
    "\n",
    "    \n",
    "# Time to drink some coffee!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я остановила, так как кажется, улучшений особо не предвидится. Летающая штука научилась летать и не хочет приземляться. Возможно, можно попробовать улучшить скор, запустив еще несколько раз (рандом!), или же увеличить рандом путем выбора эпсилона."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:27:45,373] Making new env: LunarLander-v2\n",
      "[2017-11-04 23:27:45,408] Starting new video recorder writing to /home/nimloth/coding/7sem/machine_learning_7sem/hw5/records/openaigym.video.162.3688.video000000.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-148.41183050625034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:28:25,679] Starting new video recorder writing to /home/nimloth/coding/7sem/machine_learning_7sem/hw5/records/openaigym.video.162.3688.video000001.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-176.4369182180606\n",
      "Episode finished after 1000 timesteps with reward=-138.0528507485633\n",
      "Episode finished after 1000 timesteps with reward=-133.34883995351146\n",
      "Episode finished after 1000 timesteps with reward=-165.40362593032333\n",
      "Episode finished after 1000 timesteps with reward=-139.6239676097969\n",
      "Episode finished after 1000 timesteps with reward=-151.79117423155697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:29:42,784] Starting new video recorder writing to /home/nimloth/coding/7sem/machine_learning_7sem/hw5/records/openaigym.video.162.3688.video000008.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-91.9883170035754\n"
     ]
    },
    {
     "ename": "ArgumentError",
     "evalue": "argument 2: <class 'TypeError'>: wrong type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-d6ed41ce9bc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinal_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_games\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./records\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrecord_video\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"average reward:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfinal_reward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvideo_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".mp4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./records/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nimloth/anaconda3/lib/python3.5/site-packages/agentnet/experiments/openai_gym/pool.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, n_games, save_path, use_monitor, record_video, verbose, t_max)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_memories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m                 \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 \u001b[0mtotal_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nimloth/coding/7sem/machine_learning_7sem/hw5/gym/gym/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0minfo\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcontains\u001b[0m \u001b[0mauxiliary\u001b[0m \u001b[0mdiagnostic\u001b[0m \u001b[0minformation\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhelpful\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdebugging\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msometimes\u001b[0m \u001b[0mlearning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \"\"\"\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nimloth/coding/7sem/machine_learning_7sem/hw5/gym/gym/wrappers/monitoring.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_before_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nimloth/coding/7sem/machine_learning_7sem/hw5/gym/gym/wrappers/monitoring.py\u001b[0m in \u001b[0;36m_after_step\u001b[0;34m(self, observation, reward, done, info)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats_recorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;31m# Record video\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvideo_recorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nimloth/coding/7sem/machine_learning_7sem/hw5/gym/gym/monitoring/video_recorder.py\u001b[0m in \u001b[0;36mcapture_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mrender_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ansi'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mansi_mode\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrender_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nimloth/coding/7sem/machine_learning_7sem/hw5/gym/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode, close)\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedMode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unsupported rendering mode: {}. (Supported modes for {}: {})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nimloth/coding/7sem/machine_learning_7sem/hw5/gym/gym/core.py\u001b[0m in \u001b[0;36m_render\u001b[0;34m(self, mode, close)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_render\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_close\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nimloth/coding/7sem/machine_learning_7sem/hw5/gym/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode, close)\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedMode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unsupported rendering mode: {}. (Supported modes for {}: {})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nimloth/coding/7sem/machine_learning_7sem/hw5/gym/gym/envs/box2d/lunar_lander.py\u001b[0m in \u001b[0;36m_render\u001b[0;34m(self, mode, close)\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_polygon\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflagy2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflagy2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mSCALE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflagy2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_rgb_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mLunarLanderContinuous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLunarLander\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nimloth/coding/7sem/machine_learning_7sem/hw5/gym/gym/envs/classic_control/rendering.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, return_rgb_array)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswitch_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgeom\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeoms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nimloth/anaconda3/lib/python3.5/site-packages/pyglet/window/xlib/__init__.py\u001b[0m in \u001b[0;36mdispatch_events\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    851\u001b[0m         \u001b[0;31m# Check for the events specific to this window\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         while xlib.XCheckWindowEvent(_x_display, _window,\n\u001b[0;32m--> 853\u001b[0;31m                                      0x1ffffff, byref(e)):\n\u001b[0m\u001b[1;32m    854\u001b[0m             \u001b[0;31m# Key events are filtered by the xlib window event\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# handler so they get a shot at the prefiltered event.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mArgumentError\u001b[0m: argument 2: <class 'TypeError'>: wrong type"
     ]
    }
   ],
   "source": [
    "final_reward = pool.evaluate(n_games=10,save_path=\"./records\",record_video=True)\n",
    "\n",
    "print(\"average reward:\",final_reward)\n",
    "\n",
    "video_names = list(filter(lambda s:s.endswith(\".mp4\"),os.listdir(\"./records/\")))\n",
    "\n",
    "for video_name in video_names:\n",
    "    HTML(\"\"\"\n",
    "    <video width=\"640\" height=\"480\" controls>\n",
    "      <source src=\"{}\" type=\"video/mp4\">\n",
    "    </video>\n",
    "    \"\"\".format(\"./records/\"+video_name)) #this may or may not be _last_ video. Try other indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
